{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4f3CKqFUqL2-",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Minimal example: build a model with TensorFlow estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6TjLjL9IU80G"
   },
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import shutil  # for shell utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "The data is based on 1990 census data from California. This data is at the city block level, so these features reflect the total number of rooms in that block, or the total number of people who live on that block, respectively.\n",
    "\n",
    "TensorFlow does **not** require input in the format of X and y. So keep all columns in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-114.3</td>\n",
       "      <td>34.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5612.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>66900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-114.5</td>\n",
       "      <td>34.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>1901.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>80100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>85700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>73400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>65500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0     -114.3      34.2                15.0       5612.0          1283.0   \n",
       "1     -114.5      34.4                19.0       7650.0          1901.0   \n",
       "2     -114.6      33.7                17.0        720.0           174.0   \n",
       "3     -114.6      33.6                14.0       1501.0           337.0   \n",
       "4     -114.6      33.6                20.0       1454.0           326.0   \n",
       "\n",
       "   population  households  median_income  median_house_value  \n",
       "0      1015.0       472.0            1.5             66900.0  \n",
       "1      1129.0       463.0            1.8             80100.0  \n",
       "2       333.0       117.0            1.7             85700.0  \n",
       "3       515.0       226.0            3.2             73400.0  \n",
       "4       624.0       262.0            1.9             65500.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data into dataframe\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/ml_universities/california_housing_train.csv\", sep=\",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data for train and evaluation\n",
    "np.random.seed(seed=1) #makes result reproducible\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "df_train = df[msk]\n",
    "de_eval = df[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define features\n",
    "TensorFlow requires the features to be explicitly defined based on columns available in the dataframe. There is no need to remove unused columns from the dataframe.\n",
    "\n",
    "### Add more features to the dataframe\n",
    "Analyze the data and figure out what new features to add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_more_features(df):\n",
    "    df['avg_rooms_per_house'] = df['total_rooms'] / df['households'] \n",
    "    df['avg_persons_per_room'] = df['population'] / df['total_rooms'] \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define list of feature columns\n",
    "TensorFlow requires the type of features to be explicitly specified using `tf.feature_column` API in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_cols():\n",
    "    return [tf.feature_column.numeric_column('housing_median_age'),\n",
    "            tf.feature_column.numeric_column('avg_rooms_per_house'),\n",
    "            tf.feature_column.numeric_column('avg_persons_per_room'),\n",
    "            tf.feature_column.numeric_column('median_income'),\n",
    "            tf.feature_column.bucketized_column(tf.feature_column.numeric_column('latitude'),\n",
    "                                                boundaries = np.arange(32.0, 42, 1).tolist())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make input functions\n",
    "The input function not only provision data, but also dictate how the data to be supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas input function, works in TensorFlow 1.x\n",
    "def make_input_fn(df, num_epochs):\n",
    "  return tf.compact.v1.estimator.inputs.pandas_input_fn(  # have to specify .compact.v1\n",
    "    x = add_more_features(df),\n",
    "    y = df['median_house_value'] / 100000, # will talk about why later in the course\n",
    "    batch_size = 128,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )\n",
    "\n",
    "# in TensorFlow 2.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your feature columns\n",
    "def create_feature_cols():\n",
    "  return [\n",
    "    tf.feature_column.numeric_column('housing_median_age'),\n",
    "    tf.feature_column.bucketized_column(tf.feature_column.numeric_column('latitude'), boundaries = np.arange(32.0, 42, 1).tolist()),\n",
    "    tf.feature_column.numeric_column('avg_rooms_per_house'),\n",
    "    tf.feature_column.numeric_column('avg_persons_per_room'),\n",
    "    tf.feature_column.numeric_column('median_income')\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator train and evaluate function\n",
    "def train_and_evaluate(output_dir, num_train_steps):\n",
    "  estimator = tf.estimator.LinearRegressor(model_dir = output_dir, feature_columns = create_feature_cols())\n",
    "  train_spec = tf.estimator.TrainSpec(input_fn = make_input_fn(traindf, None), \n",
    "                                      max_steps = num_train_steps)\n",
    "  eval_spec = tf.estimator.EvalSpec(input_fn = make_input_fn(evaldf, 1), \n",
    "                                    steps = None, \n",
    "                                    start_delay_secs = 1, # start evaluating after N seconds, \n",
    "                                    throttle_secs = 5)  # evaluate every N seconds\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch tensorboard\n",
    "OUTDIR = './trained_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I1106 19:45:49.214785 140356028634944 estimator.py:1790] Using default config.\n",
      "I1106 19:45:49.217272 140356028634944 estimator.py:209] Using config: {'_model_dir': './trained_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa6e2749160>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "/home/gl/tf_env/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/gl/tf_env/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "I1106 19:45:49.340904 140356028634944 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "I1106 19:45:49.341642 140356028634944 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "I1106 19:45:49.342988 140356028634944 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "W1106 19:45:49.367756 140356028634944 deprecation.py:323] From /home/gl/tf_env/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W1106 19:45:49.419399 140356028634944 deprecation.py:323] From /home/gl/tf_env/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W1106 19:45:49.424756 140356028634944 deprecation.py:323] From /home/gl/tf_env/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "I1106 19:45:49.441640 140356028634944 estimator.py:1145] Calling model_fn.\n",
      "W1106 19:45:49.952481 140356028634944 deprecation.py:323] From /home/gl/tf_env/lib/python3.7/site-packages/tensorflow/python/ops/sparse_ops.py:1719: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1106 19:45:50.286405 140356028634944 deprecation.py:323] From /home/gl/tf_env/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "I1106 19:45:50.628860 140356028634944 estimator.py:1147] Done calling model_fn.\n",
      "I1106 19:45:50.629828 140356028634944 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I1106 19:45:51.024993 140356028634944 monitored_session.py:240] Graph was finalized.\n",
      "I1106 19:45:51.291914 140356028634944 session_manager.py:500] Running local_init_op.\n",
      "I1106 19:45:51.308279 140356028634944 session_manager.py:502] Done running local_init_op.\n",
      "W1106 19:45:51.343581 140356028634944 deprecation.py:323] From /home/gl/tf_env/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "I1106 19:45:51.814593 140356028634944 basic_session_run_hooks.py:606] Saving checkpoints for 0 into ./trained_model/model.ckpt.\n",
      "I1106 19:45:53.107187 140356028634944 basic_session_run_hooks.py:262] loss = 494.1112, step = 1\n",
      "I1106 19:45:53.628669 140356028634944 basic_session_run_hooks.py:692] global_step/sec: 191.633\n",
      "I1106 19:45:53.632816 140356028634944 basic_session_run_hooks.py:260] loss = 53.06698, step = 101 (0.526 sec)\n",
      "I1106 19:45:54.049424 140356028634944 basic_session_run_hooks.py:692] global_step/sec: 237.677\n",
      "I1106 19:45:54.052273 140356028634944 basic_session_run_hooks.py:260] loss = 208.4379, step = 201 (0.419 sec)\n",
      "I1106 19:45:54.454060 140356028634944 basic_session_run_hooks.py:692] global_step/sec: 247.123\n",
      "I1106 19:45:54.456970 140356028634944 basic_session_run_hooks.py:260] loss = 62.93633, step = 301 (0.405 sec)\n",
      "I1106 19:45:54.846699 140356028634944 basic_session_run_hooks.py:692] global_step/sec: 254.707\n",
      "I1106 19:45:54.849557 140356028634944 basic_session_run_hooks.py:260] loss = 63.84876, step = 401 (0.393 sec)\n",
      "I1106 19:45:55.255354 140356028634944 basic_session_run_hooks.py:692] global_step/sec: 244.701\n",
      "I1106 19:45:55.259125 140356028634944 basic_session_run_hooks.py:260] loss = 73.25933, step = 501 (0.410 sec)\n",
      "I1106 19:45:55.656563 140356028634944 basic_session_run_hooks.py:692] global_step/sec: 249.226\n",
      "I1106 19:45:55.663400 140356028634944 basic_session_run_hooks.py:260] loss = 28.10131, step = 601 (0.404 sec)\n",
      "W1106 19:45:55.679840 140356028634944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 604 vs previous value: 604. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "W1106 19:45:55.692845 140356028634944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 606 vs previous value: 606. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "I1106 19:45:56.102404 140356028634944 basic_session_run_hooks.py:692] global_step/sec: 224.45\n",
      "I1106 19:45:56.105490 140356028634944 basic_session_run_hooks.py:260] loss = 41.85945, step = 701 (0.442 sec)\n",
      "W1106 19:45:56.140417 140356028634944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 707 vs previous value: 707. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "I1106 19:45:56.581027 140356028634944 basic_session_run_hooks.py:692] global_step/sec: 208.817\n",
      "I1106 19:45:56.584208 140356028634944 basic_session_run_hooks.py:260] loss = 109.462036, step = 801 (0.479 sec)\n",
      "I1106 19:45:57.010531 140356028634944 basic_session_run_hooks.py:692] global_step/sec: 232.821\n",
      "I1106 19:45:57.014727 140356028634944 basic_session_run_hooks.py:260] loss = 63.727238, step = 901 (0.431 sec)\n",
      "I1106 19:45:57.407370 140356028634944 basic_session_run_hooks.py:692] global_step/sec: 251.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1106 19:45:57.410668 140356028634944 basic_session_run_hooks.py:260] loss = 153.61343, step = 1001 (0.396 sec)\n",
      "I1106 19:45:57.808362 140356028634944 basic_session_run_hooks.py:692] global_step/sec: 249.357\n",
      "I1106 19:45:57.811183 140356028634944 basic_session_run_hooks.py:260] loss = 123.540054, step = 1101 (0.401 sec)\n",
      "W1106 19:45:58.162163 140356028634944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1186 vs previous value: 1186. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "I1106 19:45:58.224290 140356028634944 basic_session_run_hooks.py:692] global_step/sec: 240.429\n",
      "I1106 19:45:58.225600 140356028634944 basic_session_run_hooks.py:260] loss = 62.471573, step = 1201 (0.414 sec)\n",
      "I1106 19:45:58.620387 140356028634944 basic_session_run_hooks.py:692] global_step/sec: 252.458\n",
      "I1106 19:45:58.622113 140356028634944 basic_session_run_hooks.py:260] loss = 59.272453, step = 1301 (0.396 sec)\n",
      "I1106 19:45:59.008552 140356028634944 basic_session_run_hooks.py:692] global_step/sec: 257.628\n",
      "I1106 19:45:59.011987 140356028634944 basic_session_run_hooks.py:260] loss = 37.07887, step = 1401 (0.390 sec)\n",
      "W1106 19:45:59.021926 140356028634944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1402 vs previous value: 1402. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "I1106 19:45:59.418833 140356028634944 basic_session_run_hooks.py:692] global_step/sec: 243.767\n",
      "I1106 19:45:59.421883 140356028634944 basic_session_run_hooks.py:260] loss = 45.98745, step = 1501 (0.410 sec)\n",
      "I1106 19:45:59.920599 140356028634944 basic_session_run_hooks.py:692] global_step/sec: 199.292\n",
      "I1106 19:45:59.923682 140356028634944 basic_session_run_hooks.py:260] loss = 80.9307, step = 1601 (0.502 sec)\n",
      "I1106 19:46:00.326288 140356028634944 basic_session_run_hooks.py:692] global_step/sec: 246.489\n",
      "I1106 19:46:00.328137 140356028634944 basic_session_run_hooks.py:260] loss = 26.937447, step = 1701 (0.404 sec)\n",
      "I1106 19:46:00.726300 140356028634944 basic_session_run_hooks.py:692] global_step/sec: 249.974\n",
      "I1106 19:46:00.729563 140356028634944 basic_session_run_hooks.py:260] loss = 109.067055, step = 1801 (0.401 sec)\n",
      "I1106 19:46:01.138990 140356028634944 basic_session_run_hooks.py:692] global_step/sec: 242.35\n",
      "I1106 19:46:01.147648 140356028634944 basic_session_run_hooks.py:260] loss = 132.55933, step = 1901 (0.418 sec)\n",
      "I1106 19:46:01.609328 140356028634944 basic_session_run_hooks.py:606] Saving checkpoints for 2000 into ./trained_model/model.ckpt.\n",
      "I1106 19:46:01.842994 140356028634944 estimator.py:1145] Calling model_fn.\n",
      "I1106 19:46:02.465801 140356028634944 estimator.py:1147] Done calling model_fn.\n",
      "I1106 19:46:02.509874 140356028634944 evaluation.py:255] Starting evaluation at 2019-11-06T19:46:02Z\n",
      "I1106 19:46:02.676217 140356028634944 monitored_session.py:240] Graph was finalized.\n",
      "W1106 19:46:02.677716 140356028634944 deprecation.py:323] From /home/gl/tf_env/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I1106 19:46:02.680716 140356028634944 saver.py:1280] Restoring parameters from ./trained_model/model.ckpt-2000\n",
      "I1106 19:46:02.788270 140356028634944 session_manager.py:500] Running local_init_op.\n",
      "I1106 19:46:02.812813 140356028634944 session_manager.py:502] Done running local_init_op.\n",
      "I1106 19:46:03.335700 140356028634944 evaluation.py:275] Finished evaluation at 2019-11-06-19:46:03\n",
      "I1106 19:46:03.336558 140356028634944 estimator.py:2039] Saving dict for global step 2000: average_loss = 0.6639686, global_step = 2000, label/mean = 2.0454624, loss = 83.315765, prediction/mean = 2.2261705\n",
      "I1106 19:46:03.449851 140356028634944 estimator.py:2099] Saving 'checkpoint_path' summary for global step 2000: ./trained_model/model.ckpt-2000\n",
      "I1106 19:46:03.718622 140356028634944 estimator.py:368] Loss for final step: 79.581894.\n"
     ]
    }
   ],
   "source": [
    "# Run the model\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "tf.summary.FileWriterCache.clear() # ensure filewriter cache is clear for TensorBoard events file\n",
    "train_and_evaluate(OUTDIR, 2000)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "first_steps_with_tensor_flow.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
